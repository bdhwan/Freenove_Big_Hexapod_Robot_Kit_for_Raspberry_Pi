#!/usr/bin/env node
/**
 * LLM Robot Controller
 * ìì—°ì–´ ëª…ë ¹ì„ LLMì„ í†µí•´ í•´ì„í•˜ê³  MCPë¥¼ í†µí•´ ë¡œë´‡ì„ ì œì–´í•©ë‹ˆë‹¤.
 * 
 * ì‚¬ìš©ë²•:
 *   - Ollama ì‚¬ìš©: LLM_PROVIDER=ollama LLM_MODEL=llama3.2 npm run llm-controller
 *   - OpenAI ì‚¬ìš©: LLM_PROVIDER=openai LLM_API_KEY=your-key npm run llm-controller
 */

import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";
import axios from "axios";
import * as readline from "readline";

// í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
const LLM_PROVIDER = process.env.LLM_PROVIDER || "ollama"; // "ollama" or "openai"
const LLM_MODEL = process.env.LLM_MODEL || "llama3.2"; // Ollama ëª¨ë¸ëª…
const OPENAI_API_KEY = process.env.OPENAI_API_KEY || "";
const OPENAI_MODEL = process.env.OPENAI_MODEL || "gpt-4o-mini";
const OLLAMA_BASE_URL = process.env.OLLAMA_BASE_URL || "http://localhost:11434";
const MCP_SERVER_COMMAND = process.env.MCP_SERVER_COMMAND || "node";
const MCP_SERVER_PATH = process.env.MCP_SERVER_PATH || "./dist/mcp_server.js";

// MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
let mcpClient: Client | null = null;

/**
 * MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
 */
async function initializeMCPClient(): Promise<Client> {
  const transport = new StdioClientTransport({
    command: MCP_SERVER_COMMAND,
    args: [MCP_SERVER_PATH],
    env: {
      ROBOT_REST_API_URL: process.env.ROBOT_REST_API_URL || "http://localhost:8000",
    },
  });

  const client = new Client(
    {
      name: "llm-robot-controller",
      version: "1.0.0",
    },
    {
      capabilities: {},
    }
  );

  await client.connect(transport);
  console.log("âœ“ MCP í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨");
  return client;
}

/**
 * ë¡œë´‡ ìƒíƒœ ì¡°íšŒ
 */
async function getRobotStatus(): Promise<any> {
  if (!mcpClient) {
    throw new Error("MCP í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤");
  }

  try {
    // ì—¬ëŸ¬ ìƒíƒœ ì •ë³´ë¥¼ ì¡°íšŒ
    const [statusResult, powerResult, ultrasonicResult] = await Promise.all([
      mcpClient.callTool({
        name: "robot_get_status",
        arguments: {},
      }),
      mcpClient.callTool({
        name: "robot_get_power",
        arguments: {},
      }),
      mcpClient.callTool({
        name: "robot_get_ultrasonic",
        arguments: {},
      }),
    ]);

    const status = JSON.parse(statusResult.content[0].text);
    const power = JSON.parse(powerResult.content[0].text);
    const ultrasonic = JSON.parse(ultrasonicResult.content[0].text);

    return {
      status: status.status || "unknown",
      servo_relaxed: status.servo_relaxed || false,
      tcp_active: status.tcp_active || false,
      battery: {
        load: power.load_battery || 0,
        raspberry_pi: power.raspberry_pi_battery || 0,
      },
      distance: ultrasonic.distance || 0,
    };
  } catch (error: any) {
    console.error("ë¡œë´‡ ìƒíƒœ ì¡°íšŒ ì˜¤ë¥˜:", error.message);
    return {
      status: "unknown",
      error: error.message,
    };
  }
}

/**
 * Ollama APIë¥¼ í†µí•œ LLM í˜¸ì¶œ
 */
async function callOllama(prompt: string, systemPrompt: string): Promise<string> {
  try {
    const response = await axios.post(
      `${OLLAMA_BASE_URL}/api/chat`,
      {
        model: LLM_MODEL,
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: prompt },
        ],
        stream: false,
      },
      {
        timeout: 30000,
      }
    );

    return response.data.message.content;
  } catch (error: any) {
    throw new Error(`Ollama API ì˜¤ë¥˜: ${error.message}`);
  }
}

/**
 * OpenAI APIë¥¼ í†µí•œ LLM í˜¸ì¶œ
 */
async function callOpenAI(prompt: string, systemPrompt: string): Promise<string> {
  if (!OPENAI_API_KEY) {
    throw new Error("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤");
  }

  try {
    const response = await axios.post(
      "https://api.openai.com/v1/chat/completions",
      {
        model: OPENAI_MODEL,
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: prompt },
        ],
        temperature: 0.7,
      },
      {
        headers: {
          Authorization: `Bearer ${OPENAI_API_KEY}`,
          "Content-Type": "application/json",
        },
        timeout: 30000,
      }
    );

    return response.data.choices[0].message.content;
  } catch (error: any) {
    throw new Error(`OpenAI API ì˜¤ë¥˜: ${error.message}`);
  }
}

/**
 * LLM í˜¸ì¶œ (í”„ë¡œë°”ì´ë”ì— ë”°ë¼ ë¶„ê¸°)
 */
async function callLLM(prompt: string, systemPrompt: string): Promise<string> {
  if (LLM_PROVIDER === "openai") {
    return await callOpenAI(prompt, systemPrompt);
  } else {
    return await callOllama(prompt, systemPrompt);
  }
}

/**
 * LLM ì‘ë‹µì—ì„œ JSON ëª…ë ¹ ì¶”ì¶œ
 */
function extractCommandFromLLMResponse(response: string): any {
  // JSON ì½”ë“œ ë¸”ë¡ ì°¾ê¸°
  const jsonMatch = response.match(/```json\n([\s\S]*?)\n```/);
  if (jsonMatch) {
    try {
      return JSON.parse(jsonMatch[1]);
    } catch (e) {
      console.warn("JSON íŒŒì‹± ì‹¤íŒ¨:", e);
    }
  }

  // ì¤‘ê´„í˜¸ë¡œ ê°ì‹¸ì§„ JSON ì°¾ê¸°
  const braceMatch = response.match(/\{[\s\S]*\}/);
  if (braceMatch) {
    try {
      return JSON.parse(braceMatch[0]);
    } catch (e) {
      console.warn("JSON íŒŒì‹± ì‹¤íŒ¨:", e);
    }
  }

  // JSONì´ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ì‘ë‹µ ë°˜í™˜
  return { text: response };
}

/**
 * MCP ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
 */
async function getAvailableTools(): Promise<string> {
  if (!mcpClient) {
    throw new Error("MCP í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤");
  }

  const tools = await mcpClient.listTools();
  return JSON.stringify(
    tools.tools.map((tool) => ({
      name: tool.name,
      description: tool.description,
    })),
    null,
    2
  );
}

/**
 * ìì—°ì–´ ëª…ë ¹ì„ ë¡œë´‡ ì œì–´ ëª…ë ¹ìœ¼ë¡œ ë³€í™˜
 */
async function processNaturalLanguageCommand(userRequest: string): Promise<void> {
  try {
    // 1. ë¡œë´‡ ìƒíƒœ ì¡°íšŒ
    console.log("\nğŸ“Š ë¡œë´‡ ìƒíƒœ ì¡°íšŒ ì¤‘...");
    const robotStatus = await getRobotStatus();
    console.log("âœ“ ë¡œë´‡ ìƒíƒœ:", JSON.stringify(robotStatus, null, 2));

    // 2. ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    const availableTools = await getAvailableTools();

    // 3. LLM ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
    const systemPrompt = `ë‹¹ì‹ ì€ í—¥ì‚¬í¬ë“œ ë¡œë´‡ ì œì–´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìì—°ì–´ ëª…ë ¹ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë¡œë´‡ ì œì–´ ëª…ë ¹ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

ì‚¬ìš© ê°€ëŠ¥í•œ ë¡œë´‡ ì œì–´ ëª…ë ¹:
${availableTools}

âš ï¸ ì¤‘ìš”: ëª…ë ¹ ì²˜ë¦¬ ê·œì¹™
1. **ì´ë™ ëª…ë ¹ ì²˜ë¦¬**: 
   - ì‹œê°„ ì§€ì†ì´ í•„ìš”í•œ ì´ë™ ëª…ë ¹(ì˜ˆ: "3ì´ˆê°„ ì•ìœ¼ë¡œ ì´ë™")ì´ë‚˜ ì—°ì†ëœ ë™ì‘ì„ ìš”ì²­ë°›ìœ¼ë©´, ë°˜ë“œì‹œ 'robot_execute_sequence' ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í•œ ë²ˆì— ëª…ë ¹ì„ ë‚´ë¦¬ì„¸ìš”.
   - ì ˆëŒ€ 'robot_move'ë¥¼ ì—¬ëŸ¬ ë²ˆ ë”°ë¡œ í˜¸ì¶œí•˜ê±°ë‚˜, 'robot_move' í›„ 'wait' ë„êµ¬ë¥¼ ë”°ë¡œ í˜¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”.
   - **ì¤‘ìš”**: ë¡œë´‡ì´ ì‹¤ì œë¡œ ì´ë™í•˜ë ¤ë©´ ì´ë™ ëª…ë ¹ ì‚¬ì´ì— ëŒ€ê¸° ì‹œê°„ì´ í•„ìˆ˜ì…ë‹ˆë‹¤. ì´ë™ ëª…ë ¹ ë’¤ì—ëŠ” í•­ìƒ 'wait' ëª…ë ¹ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤. (ë³„ë„ ì‹œê°„ ì–¸ê¸‰ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ 1ì´ˆ ì´ìƒ)
   - ì´ë™ í›„ ë©ˆì¶”ëŠ” ë™ì‘ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. (ë§ˆì§€ë§‰ì— x=0, y=0 ì´ë™ ëª…ë ¹ ì¶”ê°€)
   - êµ¬ì¡°: [ì´ë™ ëª…ë ¹] -> [wait ëª…ë ¹ (í•„ìˆ˜)] -> [ì •ì§€(x=0,y=0) ëª…ë ¹]

2. **ê¸°ë³¸ íŒŒë¼ë¯¸í„°**: 
   - ì‚¬ìš©ìê°€ ë³„ë„ë¡œ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ **modeëŠ” 1**, **speedëŠ” 10(ìµœëŒ€)**ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.

ëª…ë ¹ í˜•ì‹:
- robot_move: {mode: 1|2, x: -35~35, y: -35~35, speed: 2~10, angle: -10~10}
- robot_execute_sequence: {commands: [{id, type, params}]}
  - type: move, wait, head, led, buzzer, attitude, position, camera, balance, servo_power
  - wait params: {seconds: number}
- robot_set_led_color: {r: 0~255, g: 0~255, b: 0~255}
- robot_set_led_mode: {mode: 0~5}
- robot_set_head: {servo_id: 0|1, angle: -90~90}
- robot_set_attitude: {roll: -15~15, pitch: -15~15, yaw: -15~15}
- robot_set_position: {x: -40~40, y: -40~40, z: -20~20}
- robot_set_camera: {x: -90~90, y: -90~90}
- robot_set_buzzer: {state: true|false}
- robot_set_balance: {enable: true|false}
- robot_set_servo_power: {power_on: true|false}
- robot_get_ultrasonic: {}
- robot_get_power: {}
- robot_get_status: {}

ì‘ë‹µ í˜•ì‹:
ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ëª…ë ¹ì„ ë°˜í™˜í•˜ì„¸ìš”.

ì˜ˆì‹œ 1 (ë‹¨ì¼ ëª…ë ¹):
{
  "tool": "robot_move",
  "args": {"mode": 1, "x": 10, "y": 0, "speed": 10, "angle": 0},
  "explanation": "ì•ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤ (ê¸°ë³¸ ì†ë„ 10)"
}

ì˜ˆì‹œ 2 (ì‹œí€€ìŠ¤ ëª…ë ¹ - 3ì´ˆê°„ ì•ìœ¼ë¡œ ì´ë™):
{
  "tool": "robot_execute_sequence",
  "args": {
    "commands": [
      {
        "id": "move_1",
        "type": "move",
        "params": {"mode": 1, "x": 10, "y": 0, "speed": 10, "angle": 0}
      },
      {
        "id": "wait_1",
        "type": "wait",
        "params": {"seconds": 3}
      },
      {
        "id": "stop_1",
        "type": "move",
        "params": {"mode": 1, "x": 0, "y": 0, "speed": 10, "angle": 0}
      }
    ]
  },
  "explanation": "3ì´ˆê°„ ì•ìœ¼ë¡œ ì´ë™ í›„ ì •ì§€í•©ë‹ˆë‹¤."
}`;

    // 4. ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìƒì„±
    const userPrompt = `í˜„ì¬ ë¡œë´‡ ìƒíƒœ:
${JSON.stringify(robotStatus, null, 2)}

ì‚¬ìš©ì ìš”ì²­: "${userRequest}"

ìœ„ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë¡œë´‡ ì œì–´ ëª…ë ¹ì„ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.`;

    // 5. LLM í˜¸ì¶œ
    console.log("\nğŸ¤– LLMì— ìš”ì²­ ì „ì†¡ ì¤‘...");
    const llmResponse = await callLLM(userPrompt, systemPrompt);
    console.log("âœ“ LLM ì‘ë‹µ:", llmResponse);

    // 6. ëª…ë ¹ ì¶”ì¶œ ë° ì‹¤í–‰
    const command = extractCommandFromLLMResponse(llmResponse);
    console.log("\nğŸ“ ì¶”ì¶œëœ ëª…ë ¹:", JSON.stringify(command, null, 2));

    // 7. ëª…ë ¹ ì‹¤í–‰
    if (command.commands && Array.isArray(command.commands)) {
      // ì—¬ëŸ¬ ëª…ë ¹ ì‹¤í–‰
      console.log(`\nâš™ï¸  ${command.commands.length}ê°œì˜ ëª…ë ¹ ì‹¤í–‰ ì¤‘...`);
      for (const cmd of command.commands) {
        await executeMCPCommand(cmd.tool, cmd.args);
      }
    } else if (command.tool) {
      // ë‹¨ì¼ ëª…ë ¹ ì‹¤í–‰
      console.log(`\nâš™ï¸  ëª…ë ¹ ì‹¤í–‰ ì¤‘: ${command.tool}`);
      await executeMCPCommand(command.tool, command.args);
    } else {
      console.log("\nâš ï¸  ëª…ë ¹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. LLM ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”.");
      console.log("ì‘ë‹µ:", llmResponse);
    }
  } catch (error: any) {
    console.error("\nâŒ ì˜¤ë¥˜ ë°œìƒ:", error.message);
    if (error.stack) {
      console.error("ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:", error.stack);
    }
  }
}

/**
 * MCP ëª…ë ¹ ì‹¤í–‰
 */
async function executeMCPCommand(toolName: string, args: any): Promise<void> {
  if (!mcpClient) {
    throw new Error("MCP í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤");
  }

  try {
    console.log(`  â†’ ${toolName}(${JSON.stringify(args)})`);
    const result = await mcpClient.callTool({
      name: toolName,
      arguments: args || {},
    });

    const resultText = result.content[0].text;
    const resultData = JSON.parse(resultText);

    if (result.isError) {
      console.error(`  âŒ ì˜¤ë¥˜:`, resultData);
    } else {
      console.log(`  âœ“ ì„±ê³µ:`, resultData);
    }
  } catch (error: any) {
    console.error(`  âŒ ì‹¤í–‰ ì˜¤ë¥˜:`, error.message);
    throw error;
  }
}

/**
 * ëŒ€í™”í˜• ëª¨ë“œ
 */
function startInteractiveMode(): void {
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
  });

  console.log("\n" + "=".repeat(60));
  console.log("ğŸ¤– LLM ë¡œë´‡ ì œì–´ê¸°");
  console.log("=".repeat(60));
  console.log(`LLM í”„ë¡œë°”ì´ë”: ${LLM_PROVIDER}`);
  if (LLM_PROVIDER === "ollama") {
    console.log(`ëª¨ë¸: ${LLM_MODEL}`);
  } else {
    console.log(`ëª¨ë¸: ${OPENAI_MODEL}`);
  }
  console.log("=".repeat(60));
  console.log("\nìì—°ì–´ë¡œ ë¡œë´‡ì„ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.");
  console.log("ì˜ˆì‹œ: 'ì•ìœ¼ë¡œ ì´ë™í•´ì¤˜', 'LEDë¥¼ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ ë°”ê¿”ì¤˜', 'ê±°ë¦¬ë¥¼ ì¸¡ì •í•´ì¤˜'");
  console.log("\nì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n");

  const askQuestion = () => {
    rl.question("ëª…ë ¹ ì…ë ¥ > ", async (answer) => {
      if (answer.toLowerCase() === "exit" || answer.toLowerCase() === "quit") {
        console.log("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.");
        rl.close();
        if (mcpClient) {
          await mcpClient.close();
        }
        process.exit(0);
      }

      if (answer.trim()) {
        await processNaturalLanguageCommand(answer.trim());
      }

      console.log(""); // ë¹ˆ ì¤„ ì¶”ê°€
      askQuestion();
    });
  };

  askQuestion();
}

/**
 * ëª…ë ¹ì¤„ ì¸ì ëª¨ë“œ
 */
async function processCommandLineArgs(): Promise<void> {
  const args = process.argv.slice(2);
  if (args.length === 0) {
    console.error("ì‚¬ìš©ë²•: npm run llm-controller <ìì—°ì–´ ëª…ë ¹>");
    console.error("ì˜ˆì‹œ: npm run llm-controller 'ì•ìœ¼ë¡œ ì´ë™í•´ì¤˜'");
    process.exit(1);
  }

  const userRequest = args.join(" ");
  await processNaturalLanguageCommand(userRequest);

  if (mcpClient) {
    await mcpClient.close();
  }
}

/**
 * ë©”ì¸ í•¨ìˆ˜
 */
async function main() {
  try {
    // MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    console.log("ğŸ”Œ MCP ì„œë²„ì— ì—°ê²° ì¤‘...");
    mcpClient = await initializeMCPClient();

    // ëª…ë ¹ì¤„ ì¸ìê°€ ìˆìœ¼ë©´ ì‹¤í–‰í•˜ê³  ì¢…ë£Œ, ì—†ìœ¼ë©´ ëŒ€í™”í˜• ëª¨ë“œ
    if (process.argv.length > 2) {
      await processCommandLineArgs();
    } else {
      startInteractiveMode();
    }
  } catch (error: any) {
    console.error("âŒ ì¹˜ëª…ì  ì˜¤ë¥˜:", error.message);
    if (error.stack) {
      console.error("ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:", error.stack);
    }
    process.exit(1);
  }
}

// í”„ë¡œê·¸ë¨ ì‹¤í–‰
main();

